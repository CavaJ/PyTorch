{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9fc209d",
   "metadata": {},
   "source": [
    "# Demo: Creating and Initializing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85f78d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a5065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch's default data type\n",
    "\n",
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73deb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeError: only floating-point types are supported as the default type (when torch.int is passed as an function argument)\n",
    "# torch.set_default_dtype(torch.int)\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61e02e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6fba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Toolkit version: 11.3\n",
      "Cuda available: False\n",
      "Cuda device count: 0\n"
     ]
    }
   ],
   "source": [
    "# print the version of CUDA being used by pytorch\n",
    "print(\"Cuda Toolkit version:\", torch.version.cuda)\n",
    "print(\"Cuda available:\", torch.cuda.is_available())\n",
    "print(\"Cuda device count:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    curr_device = torch.cuda.current_device()\n",
    "    print(\"Cuda current device:\", curr_device)\n",
    "    print(\"Cuda device name:\", torch.cuda.get_device_name(curr_device))\n",
    "    print(\"Cuda device properties:\", torch.cuda.get_device_properties(curr_device))\n",
    "    # 7.5\n",
    "    print(\"Cuda compute capability:\", torch.cuda.get_device_capability(curr_device))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(curr_device)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(curr_device)/1024**3,1), 'GB')\n",
    "\n",
    "    torch.cuda.memory_allocated(curr_device)\n",
    "\n",
    "\n",
    "    # torch.cuda.memory_reserved(curr_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f260f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a torch tensor by specifiying Python list as its input\n",
    "# when we use torch.tensor, it is an alias for the default tensor type, namely torch.FloatTensor()\n",
    "tensor_arr = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df71c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether the particular python object is a torch tensor\n",
    "torch.is_tensor(tensor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98af731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of elements in torch tensor no matter what its size and shape\n",
    "torch.numel(tensor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1291cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.1989e-91, 6.5303e-42],\n",
       "        [6.5495e-43, 8.6044e-43]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When you specify torch.Tensor and you only indicate the shape of the tensor, the resulting tensor object will be uninitialized\n",
    "tensor_uninitialized = torch.Tensor(2, 2)\n",
    "\n",
    "# this means that behind the scenes PyTorch will allocate the memory for this tensor\n",
    "# but it won't set up any initial values because you have not specified any\n",
    "tensor_uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14687d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4202, 0.2169],\n",
       "        [0.1307, 0.2994]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.rand will initialize the tensor with random values,\n",
    "# this is a quick and easy way to initialize the weights of your model parameters\n",
    "tensor_initialized = torch.rand(2, 2)\n",
    "tensor_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d34d19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int tensor on cpu\n",
    "tensor_int = torch.tensor([5, 3]).type(torch.IntTensor)\n",
    "tensor_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a34fce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int tensor on gpu\n",
    "# tensor_int = torch.tensor([5, 3]).type(torch.cuda.IntTensor)\n",
    "# del tensor_int\n",
    "# torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aad6b971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_short = torch.ShortTensor([1, 2, 3])\n",
    "tensor_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4192c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch also has support for tensors of type torch.half. This is a floating point tensor which occupies half as much memory\n",
    "# for each element as a float32, which means these are float16 elements.\n",
    "tensor_float = torch.tensor([1, 2, 3]).type(torch.half)\n",
    "tensor_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "537b9741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_fill = torch.full((2, 6), fill_value=10)\n",
    "tensor_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1912a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_of_ones = torch.ones((2, 4), dtype=torch.int32)\n",
    "tensor_of_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecab463d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the tensor of zeroes in the size, shape and data type of tensor_of_ones\n",
    "tensor_of_zeros = torch.zeros_like(tensor_of_ones)\n",
    "tensor_of_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10882239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.eye will create two dimensional square matrix with the main diagonal filled with 1s.\n",
    "tensor_eye = torch.eye(5)\n",
    "tensor_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f7dabd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3],\n",
       "        [4, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you already have a tensor instantiated and you want to figure out at what indices the nonzero elements lie, \n",
    "# you can call torch.nonzero function.\n",
    "non_zero = torch.nonzero(tensor_eye)\n",
    "# will show [i, j] indices of non-zero elements\n",
    "non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80ec64d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1],\n",
       "        [2, 2, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tensor() always makes a copy of the underlying data of the tensor\n",
    "# torch.tensor() can be used to copy existing tensor or numpy array or list.\n",
    "# torch.tensor infers the dtype automatically, while torch.Tensor returns a torch.FloatTensor.\n",
    "# I would recommend to stick to torch.tensor, which also has arguments like dtype, if you would like to change the type.\n",
    "i = torch.tensor([[0, 1, 1], \n",
    "                  [2, 2, 0]])\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0884ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], dtype=torch.float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([3, 4, 5], dtype=torch.float32)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78a94161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 2, 0]]),\n",
      "       values=tensor([3., 4., 5.]),\n",
      "       size=(2, 5), nnz=3, dtype=torch.float32, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 2, 0]]),\n",
      "       values=tensor([3., 4., 5.]),\n",
      "       size=(2, 5), nnz=3, dtype=torch.float32, layout=torch.sparse_coo)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3., 0., 0.],\n",
       "        [5., 0., 4., 0., 0.]], dtype=torch.float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensors i and v above are dense tensors; all of the elements have usually nonzero values.\n",
    "# PyTorch also has a support for sparse tensors which are very commonly used. When you build your machine learning models,\n",
    "# your data may not always be dense, it would be sparse data and you might want to use a sparse tensor.\n",
    "# The sparse_coo_tensor function constructs a sparse tensor in coordinate format. The non-zero elements are at the indices\n",
    "# that you specify that is i, with the given values that you specified, which is the variable v. The resulting sparse tensor is\n",
    "# of shape 2, 5.\n",
    "\n",
    "# The tensor i that we had instantiated earlier specifies the indices at which sparse tensor contains data. And the tensor v \n",
    "# specifies the values contained in the sparse tensor.\n",
    "sparse_tensor = torch.sparse_coo_tensor(i, v, (2, 5))\n",
    "print(sparse_tensor)\n",
    "\n",
    "\n",
    "# Every PyTorch tensor has the .data variable, which you can use to access the underlying matrix.\n",
    "print(sparse_tensor.data)\n",
    "\n",
    "\n",
    "# To see what its dense equivalent contains\n",
    "# Unspecified elements in sparse_tensor are assumed to have the same value, fill value, which is zero by default.\n",
    "# (0, 2) => 3, (1, 2) => 4, (1, 0) => 5; the rest will be zero\n",
    "sparse_tensor.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "384ed9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[0, 1, 2, 0, 2],\n",
      "                       [0, 1, 2, 2, 0]]),\n",
      "       values=tensor([89, 21, 33, 57, 94]),\n",
      "       size=(4, 5), nnz=5, layout=torch.sparse_coo)\n",
      "tensor([[89,  0, 57,  0,  0],\n",
      "        [ 0, 21,  0,  0,  0],\n",
      "        [94,  0, 33,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Another example for sparse tensors\n",
    "indices = torch.tensor([[0, 1, 2, 0, 2],\n",
    "                        [0, 1, 2, 2, 0]])\n",
    "# print(indices.shape)\n",
    "\n",
    "# Seed everything\n",
    "# seed = 7\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.randint.html\n",
    "values = torch.tensor([89, 21, 33, 57, 94])\n",
    "s = torch.sparse_coo_tensor(indices, values, (4, 5))\n",
    "print(s)\n",
    "print(s.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac4eb9",
   "metadata": {},
   "source": [
    "# Demo: Simple Operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ffe2d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6623, 0.1780, 0.1433],\n",
       "        [0.5077, 0.3822, 0.5270]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor = torch.rand(2, 3)\n",
    "\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5f4cea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [10., 10., 10.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operations (functions) that modify the tensor in-place have an \"_\" suffix\n",
    "initial_tensor.fill_(10)\n",
    "\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93797fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6623, 0.1780, 0.1433])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b97e395f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'fill'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4776\\4005949108.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# there is no corresponding out-of-place fill operation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minitial_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'fill'"
     ]
    }
   ],
   "source": [
    "# there is no corresponding out-of-place fill operation\n",
    "initial_tensor.fill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de4a989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [10., 10., 10.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45c1b543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new:\n",
      " tensor([[15., 15., 15.],\n",
      "        [15., 15., 15.]])\n",
      "initial:\n",
      " tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.]])\n"
     ]
    }
   ],
   "source": [
    "# add 5 to every element of the initial tensor, this is out-of_place operation\n",
    "new_tensor = initial_tensor.add(5)\n",
    "print(\"new:\\n\", new_tensor)\n",
    "print(\"initial:\\n\", initial_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23cf95d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18., 18.],\n",
       "        [18., 18., 18.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-place add operation with _ suffix. Will modify initial_tensor itself.\n",
    "initial_tensor.add_(8)\n",
    "\n",
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f46a8d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 15., 15.],\n",
       "        [15., 15., 15.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ae51b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8730, 3.8730, 3.8730],\n",
       "        [3.8730, 3.8730, 3.8730]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-place square root operation\n",
    "new_tensor.sqrt_()\n",
    "\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c200cefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "<class 'torch.Tensor'>\n",
      "torch.DoubleTensor\n",
      "tensor([ 0.1000,  0.8071,  1.5143,  2.2214,  2.9286,  3.6357,  4.3429,  5.0500,\n",
      "         5.7571,  6.4643,  7.1714,  7.8786,  8.5857,  9.2929, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "# You will find that a number of operations which are very similar to Numpy are available with torch tensors as well.\n",
    "# such as torch.linspace will generate evenly spaced numbers between 0.1 and 10 here.\n",
    "\n",
    "x = torch.linspace(start=0.1, end=10.0, steps=15)\n",
    "print(len(x))\n",
    "print(type(x))\n",
    "print(x.type())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a38a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1000, 0.8071, 1.5143, 2.2214, 2.9286]),\n",
       " tensor([3.6357, 4.3429, 5.0500, 5.7571, 6.4643]),\n",
       " tensor([ 7.1714,  7.8786,  8.5857,  9.2929, 10.0000]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use torch.chunk to chunk our x tensor into three separate parts, it is out-of-place operation, \n",
    "# no \"_\" suffix at the end.\n",
    "# funtion signature: torch.chunk(input, chunks, dim=0) → List of Tensors.\n",
    "# input (Tensor) – the tensor to split\n",
    "# chunks (int) – number of chunks to return\n",
    "# dim (int) – dimension along which to split the tensor\n",
    "\n",
    "tensor_chunk = torch.chunk(x, 3, 0)\n",
    "\n",
    "print(type(tensor_chunk))\n",
    "\n",
    "# a tuple of 3 separate tensors of length 5 each\n",
    "tensor_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b870c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.8071, 1.5143, 2.2214, 2.9286, 3.6357, 4.3429, 5.0500, 5.7571,\n",
       "        6.4643, 3.0000, 4.0000, 5.0000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use torch.cat to concatenate tensors\n",
    "tensor1 = tensor_chunk[0]\n",
    "tensor2 = tensor_chunk[1]\n",
    "tensor3 = torch.tensor([3., 4., 5.])\n",
    "\n",
    "# concatenate on dim = 0. all other dimensions must have the same shape except for the concatenating dimension.\n",
    "torch.cat((tensor1, tensor2, tensor3), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01289f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  8., 30.],\n",
       "        [40.,  5.,  6.],\n",
       "        [12.,  2., 21.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.Tensor([[10, 8, 30], [40, 5, 6], [12, 2, 21]])\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6af8daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use the square bracket notation to index into Pytorch tensors to access specific elements.\n",
    "# obtain element and row i and column j.\n",
    "# observe that indexing into PyTorch tensor gives us a tensor as the result.\n",
    "random_tensor[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dca4cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "\n",
      "tensor(10.)\n",
      "tensor(8.)\n",
      "tensor(30.)\n",
      "tensor(40.)\n",
      "tensor(5.)\n",
      "tensor(6.)\n",
      "tensor(12.)\n",
      "tensor(2.)\n",
      "tensor(21.)\n"
     ]
    }
   ],
   "source": [
    "# for multi-dimensional tensors len() returns the first dimension's size\n",
    "print(len(random_tensor), \"\\n\")\n",
    "\n",
    "# go over all rows and cols in tensor\n",
    "for i in range(0, len(random_tensor)):\n",
    "    for j in range(0, len(random_tensor[i])):\n",
    "        print(random_tensor[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d29b05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 2., 21.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use tensors with array slicing operations as you would with Numpy.\n",
    "\n",
    "# Here we are accessing all of the rows from row 1 onwards and all of the columns from column 1 onwards\n",
    "random_tensor[1:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c932134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  8., 30.],\n",
       "        [40.,  5.,  6.],\n",
       "        [12.,  2., 21.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c15929b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Size'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .size function on a tensor will give us the size of tensor along each of its dimensions. \n",
    "# Return value is of type torch.Size\n",
    "print(type(random_tensor.size()))\n",
    "random_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a460b75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  8., 30., 40.,  5.,  6., 12.,  2., 21.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor.view(*shape) → Tensor\n",
    "# parameters: shape (torch.Size or int...) – the desired size\n",
    "\n",
    "# If you want to view a particular tensor using a different shape, you can use the view function.\n",
    "# Be mindful that the view function does NOT create a new tensor, it uses the same underlying memory as the original tensor.\n",
    "# view() reshapes the tensor without copying memory, similar to numpy's reshape().\n",
    "resized_tensor = random_tensor.view(9) # view it as a 1-D tensor with 9 elements\n",
    "\n",
    "resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a533ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff970b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10.,   8.,  30.],\n",
      "        [ 40.,   5.,   6.],\n",
      "        [ 12.,   2., 100.]])\n",
      "tensor([ 10.,   8.,  30.,  40.,   5.,   6.,  12.,   2., 100.])\n"
     ]
    }
   ],
   "source": [
    "# Let's now satisfy ourselves that the original tensor and our view of it share the same underlying memory.\n",
    "random_tensor[2, 2] = 100;\n",
    "\n",
    "print(random_tensor)\n",
    "print(resized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29590639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# Just like with Numpy arrays, a quick way to view the shape of a particular tensor is to call tensor.shape.\n",
    "# returns the same result as we call size() function\n",
    "print(random_tensor.shape)\n",
    "print(resized_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2371a6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10.,   8.,  30.],\n",
       "        [ 40.,   5.,   6.],\n",
       "        [ 12.,   2., 100.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ccfc3dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 10.],\n",
       "         [  8.],\n",
       "         [ 30.]],\n",
       "\n",
       "        [[ 40.],\n",
       "         [  5.],\n",
       "         [  6.]],\n",
       "\n",
       "        [[ 12.],\n",
       "         [  2.],\n",
       "         [100.]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can change the shape of a tensor in PyTorch by removing and adding dimensions using squeeze and unsqueeze operations.\n",
    "# unsqueeze operation that will add an additional dimension to the random_tensor\n",
    "tensor_unsqueeze = torch.unsqueeze(random_tensor, 2)\n",
    "\n",
    "# it made the tesnor to have shape of 3 x 3 x 1\n",
    "print(tensor_unsqueeze.shape)\n",
    "\n",
    "# new dimension is added at index 2, which will be the inner most dimension.\n",
    "tensor_unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73fea3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 10.,   8.,  30.]],\n",
       "\n",
       "        [[ 40.,   5.,   6.]],\n",
       "\n",
       "        [[ 12.,   2., 100.]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make create tensor of shape 3 x 1 x 3 from random_tensor\n",
    "\n",
    "tensor_unsqueeze1 = torch.unsqueeze(random_tensor, 1)\n",
    "print(tensor_unsqueeze1.shape)\n",
    "\n",
    "tensor_unsqueeze1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "873a3618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18., 18.],\n",
       "        [18., 18., 18.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e17ad5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18.],\n",
       "        [18., 18.],\n",
       "        [18., 18.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now perform a transpose operation which will allow use to flip dimensions in this tensor\n",
    "tensor_transpose = torch.transpose(initial_tensor, 0, 1)\n",
    "\n",
    "# now we have 3 x 2 tensor, transposed from 3 x 2 tensor.\n",
    "tensor_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e5ca2",
   "metadata": {},
   "source": [
    "# Demo: Elementwise and Matrix Operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804f4bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10.,   8.,  30.],\n",
       "        [ 40.,   5.,   6.],\n",
       "        [ 12.,   2., 100.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516790a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  8.,  10.,  30.],\n",
      "        [  5.,   6.,  40.],\n",
      "        [  2.,  12., 100.]])\n",
      "tensor([[1, 0, 2],\n",
      "        [1, 2, 0],\n",
      "        [1, 0, 2]])\n"
     ]
    }
   ],
   "source": [
    "# It is possible for you to sort your tensors based on the values on its elements by calling torch.sort.\n",
    "# It returns a named tuple of (values, indices), where values are the sorted values and indices \n",
    "# are the indices of the elements in the original input tensor.\n",
    "# You can, in addition, specify a dimension along which you want your tensor sorted.\n",
    "# If dim parameter is not given, the last dimension of the input is chosen. By default dim=-1.\n",
    "\n",
    "# here the tensor will be sorted along the dim = 1 which is its last dimension, in other words it will be sorted along the row.\n",
    "# dim = 1 means, sorts the valus in columns along the row.\n",
    "# dim = 0 means, sorts the values in rows along a column.\n",
    "sorted_tensor, sorted_indices = torch.sort(random_tensor)\n",
    "\n",
    "print(sorted_tensor)\n",
    "\n",
    "# sorted indices will give you index positions from the original tensor, but in a sorted order. \n",
    "# Indices are column indices obtained from original tensor showing the original index of the sorted value.\n",
    "print(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eaac2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1000, -2.2000,  3.3000], dtype=torch.float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float = torch.FloatTensor([-1.1, -2.2, 3.3])\n",
    "\n",
    "tensor_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe879e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1000, 2.2000, 3.3000], dtype=torch.float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.abs  for absolute values\n",
    "tensor_abs = torch.abs(tensor_float)\n",
    "\n",
    "tensor_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1b0310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0481, 0.5333, 0.3703],\n",
      "        [0.6363, 0.1609, 0.6487]])\n",
      "tensor([[1.6744, 0.1938, 2.3027],\n",
      "        [0.8423, 0.1649, 1.0542]])\n"
     ]
    }
   ],
   "source": [
    "# torch.randn() Returns a tensor filled with random numbers from a normal distribution with\n",
    "# mean 0 and variance 1 (also called the standard normal distribution).\n",
    "\n",
    "rand1 = torch.abs(torch.randn(2, 3))\n",
    "rand2 = torch.abs(torch.randn(2, 3))\n",
    "\n",
    "print(rand1)\n",
    "print(rand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b70ed54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7225, 0.7271, 2.6730],\n",
       "        [1.4785, 0.3258, 1.7030]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise addition of two matrices (tensors)\n",
    "add1 = rand1 + rand2\n",
    "\n",
    "add1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd02c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7225, 0.7271, 2.6730],\n",
       "        [1.4785, 0.3258, 1.7030]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are of course torch functions available for all kinds of mathematical operations\n",
    "add2 = torch.add(rand1, rand2)\n",
    "\n",
    "add2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb4a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -2., -3.],\n",
       "        [ 1.,  2.,  3.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.Tensor([[-1, -2, -3],\n",
    "                      [1, 2, 3]])\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb07817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7000, -1.7000, -2.7000],\n",
      "        [ 1.3000,  2.3000,  3.3000]])\n",
      "tensor([[-1., -2., -3.],\n",
      "        [ 1.,  2.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "# add 0.3 to every element of the tensor, however original tensor is untouched\n",
    "print(tensor + 0.3)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be694e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4286, 1.1765, 1.1111],\n",
       "        [0.7692, 0.8696, 0.9091]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.div operation to perform elementwise division\n",
    "tensor_div = torch.div(tensor, tensor + 0.3)\n",
    "\n",
    "tensor_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cccf7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 9.],\n",
       "        [1., 4., 9.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elementwise multiplication\n",
    "tensor_mul = torch.mul(tensor, tensor)\n",
    "\n",
    "tensor_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42d525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2000, -0.2000, -0.2000],\n",
       "        [ 1.0000,  2.0000,  2.0000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A very useful operation performed on a tensor, which is often used you are building machine learning models \n",
    "# is the clamp operation. It clamps all elements in input into the range [ min, max ].\n",
    "\n",
    "tensor_clamp = torch.clamp(tensor, min=-0.2, max=2)\n",
    "\n",
    "# all values smaller then min will be replaced by min, all value greater than max will be replaced by max\n",
    "tensor_clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "913bd06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([10., 20.])\n"
     ]
    }
   ],
   "source": [
    "# In addition to element-wise operations, you can also perform matrix operations on PyTorch Tensors.\n",
    "\n",
    "# torch.Tensor() is a constructor for creating a new tensor object in PyTorch. When you pass a list of values to \n",
    "# this constructor, it creates a 1-dimensional tensor containing the provided values\n",
    "t1 = torch.Tensor([1, 2])\n",
    "t2 = torch.Tensor([10, 20])\n",
    "\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12023d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The torch.dot function allows to calculate the dot_product of these two matrices.\n",
    "dot_product = torch.dot(t1, t2)\n",
    "\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3da8478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "# multidimensional tensor which is a matrix\n",
    "matrix = torch.Tensor([[1, 2, 3],\n",
    "                      [4, 5, 6]])\n",
    "\n",
    "# single dimensional tensor which is a vector\n",
    "vector = torch.Tensor([0, 1, 2])\n",
    "\n",
    "print(matrix)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d3b84fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 17.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mv will multiply the matrix by the corresponding vector. For multiplication, the number of columns of the first tensor\n",
    "# should be equal to the size of seconf tensor (if it is a vector) or the number of rows in the second tensor \n",
    "# (if it is a matrix)\n",
    "# for example if you multiple 2x3 matrix with 3x1 matrix, you will obtain 2x1 matrix as a result. If one is its dimensions \n",
    "# become 1, then resulting tensor will still be vector.\n",
    "# Respective elements will be multiplied.\n",
    "\n",
    "# their shapes should be compatible; the number of elements in our vector is compatible with the number of elements\n",
    "# in the second dimension of our matrix.\n",
    "\n",
    "# resulting matrix: [[1 * 0 + 2 * 1 + 3 * 2],\n",
    "#                    [4 * 0 + 5 * 1, 6 * 2]]\n",
    "# which is [[8],\n",
    "#          [17]] and can be considered as [8, 17].\n",
    "matrix_vector = torch.mv(matrix, vector)\n",
    "\n",
    "matrix_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d65312a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 50., 180.],\n",
       "        [140., 420.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use torch.mm operation if you want to perform a matrix multiplication between two matrices\n",
    "\n",
    "another_matrix = torch.Tensor([[10, 30],\n",
    "                               [20, 0],\n",
    "                               [0, 50]])\n",
    "\n",
    "# another_matrix has a shape of 3x2 which is compatible with matrix's shape 2x3, the number of elements in the second dimension\n",
    "# of the first matrix should be equal to the number of elements in the first dimennsion of the second matrix.\n",
    "# multiplication happens like this row1_matrix1 * column1_matrix2, row1_matrix1 * column2_matrix2, etc...\n",
    "matrix_mul = torch.mm(matrix, another_matrix)\n",
    "\n",
    "matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54a62415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The torch.argmax function will find you the largest element along a particular dimension\n",
    "# returns the indices of the maximum values of a tensor across a dimension.\n",
    "# If dim = 1, we will look at the columns in the following matrix along each row.\n",
    "# returns an indice of max value at the given particular dimension, in our case 180 - 1, 420 - 1. 1 means second column.\n",
    "torch.argmax(matrix_mul, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62ae1e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets consider dim=0\n",
    "# max values along dim=0, are 140 - 1, 420 - 1. 1 means second row.\n",
    "torch.argmax(matrix_mul, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84237ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[130., 170., 210.],\n",
       "        [ 20.,  40.,  60.],\n",
       "        [200., 250., 300.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_mul2 = torch.mm(another_matrix, matrix)\n",
    "\n",
    "matrix_mul2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "085e546e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max values along dim=0 are 200 - 2, 250 - 2, 300 - 2. 2 means 3rd row.\n",
    "torch.argmax(matrix_mul2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e97e7491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max values along dim=1 are 210 - 2, 60 - 2, 300 - 2. 2 means 3rd column.\n",
    "torch.argmax(matrix_mul2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4097fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([1, 1, 1])\n",
      "tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Similarly torch.argmin will give you the index of the smallest element along a particular dimension\n",
    "\n",
    "# 50 - 0, 180 - 0; 0 - first row.\n",
    "print(torch.argmin(matrix_mul, dim=0))\n",
    "# 50 - 0, 140 - 0; 0 - first column.\n",
    "print(torch.argmin(matrix_mul, dim=1))\n",
    "\n",
    "# 20 - 1, 40 - 1, 60 - 1; 1 - second row\n",
    "print(torch.argmin(matrix_mul2, dim=0))\n",
    "# 130 - 0, 20 - 0, 200 - 0; 0 - first column.\n",
    "print(torch.argmin(matrix_mul2, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb2284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
